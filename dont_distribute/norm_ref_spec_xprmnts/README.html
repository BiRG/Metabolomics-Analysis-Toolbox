<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
  <meta http-equiv="CONTENT-TYPE" content="text/html; charset=us-ascii">

  <title>Readme for normalization reference spectrum experiments</title>
  <style type="text/css">
    .ra {background-color: #FCF6CF; }
    td.id {font-family: monospace; }
    td {vertical-align:text-top; }
  </style>
</head>

<body dir="ltr" lang="en-US">
  <h1>Readme for normalization reference spectrum experiments</h1>

  <p>This directory contains my experiments, results and write-ups on
  the effects of making different choices in creating the reference
  spectra for normalization methods. Primarily these are focused on
  Probabilistic Quotient Normalization (PQN), but Histogram Normalization
  (HN) also uses a reference spectrum.</p>

  <h2>Experiment 1: using the controls or all spectra to generate the
  reference spectrum for PQN</h2>

  <p>This experiment is mainly a proof of concept, illustrating that
  using control spectra to generate the reference spectra can produce
  spurious differences between normalized control and treatment groups
  due to small sample-size effects.</p>

  <h3>Methods</h3>

  <p>In this experiment, random, synthetic data was generated for
  90,000 trials testing 9 different experimental conditions for a
  total of 10,000 spectra per condition. Each trial generated 10
  spectra from the same distribution. The 9 conditions were the number
  of spectra called "control" and the number called "treatment."  In
  the first condition, the first spectrum is called "control" and the
  rest are called "treatment." In the second, the first two spectra
  are "control". And so forth.</p>

  <p>In each trial, normalized spectra are generated by several
  different methods:
    <ol>
      <li>No normalization - the spectra are created already
      normalized, so this corresponds to the ground-truth.</li>
      <li>Sum normalization - the spectra are normalized to have a sum
      of 1000.</li>
      <li>PQN with control reference - the control group is used to
      generate a reference spectrum for PQN after Sum-normalization to
      1000.</li>
      <li>PQN with all reference - the all spectra are used together to 
      generate a reference spectrum for PQN after Sum-normalization to
      1000.</li>
    </ol>
  </p>
  <p>Then, for each normalization method, the spectra are projected
  onto their first two principal components (reflecting the normal
  analysis method). These coordinates are then scaled and translated
  to the unit square (subtract the minimum of each coordinate and
  divide by the maximum). The scaling takes care of the fact that
  normalization is unique only up to a constant scaling factor. (That
  is, if a and b are spectra and x and y are correct normalization
  constants, then cx and cy for all positive c are also correct
  normalization constants.) The translation is not strictly necessary
  but it was easier to do the scaling with it and it does not make a
  difference to distance computations. Finally and the distances
  between the centroids are of the control and treatment groups are
  computed.
  </p>

  <h3>Analysis</h3>
  <h4>Experimental Question</h4>
  <p>The question I want to answer is whether the distance between the
    normalized "control" and "treatment" groups (measured as the
    distance between their centroids) increases over the distance for
    the unnormalized (gold-standard) data. </p>

  <h4>Choosing a test</h4>

  <p>Squaring and taking the square root in distance calculations
  destroys Gaussian distribution assumptions. I verified this by
  running a small experiment with one experimental condition (4
  controls) and 1000 trials which did not calculate the all-samples
  reference spectrum condition. The Lilliefors test rejected normality
  of the distance distributions of the sum normalized and
  gold-standard methods at a 1.67% level (5% with a Bonferroni
  correction). It did not reject normality for the control-group
  reference PQN.</p>

  <p>Since the experimental design has paired samples, I initially
  wanted to use the Wilcoxon Signed Rank test on the differences to
  check whether the median of the differences is 0. However, (the
  online resources are a bit ambiguious) it seems that the test
  requires that the differences be from a symmetric distribution. A
  quick look at the histograms of the differences reveals that they
  are quite skewed. This leaves the unpaired Mann-Whitney-Wilcoxon
  rank-sum test (which tests the odds of a sample from population one
  being greater than one from population two) or the paired sign test
  which tests whether the medians of the two populations are
  equal. The Friedman test sounds promising at first blush but it
  requires identical distributions except for location shifts.</p>



  <h4>Choosing significance level</h4>

  <p>For each experimental condition I performed 3 tests of the median
  distance-differences. I'd like to limit the error on all three
  simultaneously. So, I need a multiple test correction. Since I
  believe these three questions to be independent, I used the
  &Scaron;id&aacute;k correction to control for multiple testing and
  give a family-wise Type-I error rate of &alpha;=5% for each
  experimental condition. This led me to use a nominal &alpha; of
  1.70% , which is slightly higher than the Bonferroni correction
  &alpha; (for dependent measurements) of 1.67%. I decided to leave
  each experimental condition as it's own test with a 5% chance of
  having a wrong result, so I did not do a correction for the 9
  conditions. If I had, the required &alpha; would be 0.19%
  (0.00189795 if they are independent and 0.0018836 if dependent)</p>
  
  <p>I was torn about not doing the full correction for 27
  simultaneous tests, but I don't want to increase my Type II error
  too much.</p>

  <h3>Results</h3>

  I'll have to wait until I generate them to write this section.

</body>
</html>
